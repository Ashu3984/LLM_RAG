{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/OpenAccess-AI-Collective/axolotl.git","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:32:05.540325Z","iopub.execute_input":"2023-12-22T05:32:05.541040Z","iopub.status.idle":"2023-12-22T05:32:07.553706Z","shell.execute_reply.started":"2023-12-22T05:32:05.541013Z","shell.execute_reply":"2023-12-22T05:32:07.552594Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'axolotl'...\nremote: Enumerating objects: 8416, done.\u001b[K\nremote: Counting objects: 100% (4001/4001), done.\u001b[K\nremote: Compressing objects: 100% (975/975), done.\u001b[K\nremote: Total 8416 (delta 3343), reused 3067 (delta 3022), pack-reused 4415\u001b[K\nReceiving objects: 100% (8416/8416), 2.77 MiB | 14.10 MiB/s, done.\nResolving deltas: 100% (5508/5508), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd axolotl","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:32:27.349913Z","iopub.execute_input":"2023-12-22T05:32:27.350798Z","iopub.status.idle":"2023-12-22T05:32:27.357078Z","shell.execute_reply.started":"2023-12-22T05:32:27.350760Z","shell.execute_reply":"2023-12-22T05:32:27.356158Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/axolotl\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip3 install -e .","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:32:37.427894Z","iopub.execute_input":"2023-12-22T05:32:37.428839Z","iopub.status.idle":"2023-12-22T05:37:56.696524Z","shell.execute_reply.started":"2023-12-22T05:32:37.428784Z","shell.execute_reply":"2023-12-22T05:37:56.695252Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!accelerate config default","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:37:56.698570Z","iopub.execute_input":"2023-12-22T05:37:56.698895Z","iopub.status.idle":"2023-12-22T05:38:04.108476Z","shell.execute_reply.started":"2023-12-22T05:37:56.698865Z","shell.execute_reply":"2023-12-22T05:38:04.107476Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c107WarningC1ENS_7variantIJNS0_11UserWarningENS0_18DeprecationWarningEEEERKNS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\naccelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n","output_type":"stream"}]},{"cell_type":"code","source":"!cat /root/.cache/huggingface/accelerate/default_config.yaml","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:38:04.110101Z","iopub.execute_input":"2023-12-22T05:38:04.110966Z","iopub.status.idle":"2023-12-22T05:38:05.062236Z","shell.execute_reply.started":"2023-12-22T05:38:04.110926Z","shell.execute_reply":"2023-12-22T05:38:05.061150Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{\n  \"compute_environment\": \"LOCAL_MACHINE\",\n  \"debug\": false,\n  \"distributed_type\": \"MULTI_GPU\",\n  \"downcast_bf16\": false,\n  \"machine_rank\": 0,\n  \"main_training_function\": \"main\",\n  \"mixed_precision\": \"no\",\n  \"num_machines\": 1,\n  \"num_processes\": 2,\n  \"rdzv_backend\": \"static\",\n  \"same_network\": false,\n  \"tpu_use_cluster\": false,\n  \"tpu_use_sudo\": false,\n  \"use_cpu\": false\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/Sk4467/axolotl/main/examples/mistral/qlora.yml -O /kaggle/working/axolotl/examples/mistral/qlora.yml","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:38:05.065252Z","iopub.execute_input":"2023-12-22T05:38:05.065956Z","iopub.status.idle":"2023-12-22T05:38:06.157522Z","shell.execute_reply.started":"2023-12-22T05:38:05.065898Z","shell.execute_reply":"2023-12-22T05:38:06.156339Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"--2023-12-22 05:38:05--  https://raw.githubusercontent.com/Sk4467/axolotl/main/examples/mistral/qlora.yml\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1360 (1.3K) [text/plain]\nSaving to: '/kaggle/working/axolotl/examples/mistral/qlora.yml'\n\n/kaggle/working/axo 100%[===================>]   1.33K  --.-KB/s    in 0s      \n\n2023-12-22 05:38:06 (105 MB/s) - '/kaggle/working/axolotl/examples/mistral/qlora.yml' saved [1360/1360]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!cat /kaggle/working/axolotl/examples/mistral/qlora.yml","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:38:06.159155Z","iopub.execute_input":"2023-12-22T05:38:06.159548Z","iopub.status.idle":"2023-12-22T05:38:07.093750Z","shell.execute_reply.started":"2023-12-22T05:38:06.159507Z","shell.execute_reply":"2023-12-22T05:38:07.092807Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"base_model: teknium/OpenHermes-2.5-Mistral-7B\nmodel_type: MistralForCausalLM\ntokenizer_type: LlamaTokenizer\nis_mistral_derived_model: true\n\nload_in_8bit: false\nload_in_4bit: true\nstrict: false\n\ndatasets:\n  - path: ashu3984/PHYSIGEN-phy-alpaca\n    type: alpaca:instruct\ndataset_prepared_path: last_run_prepared\nval_set_size: 0.01\nhub_model_id: ashu3984/PHYSIGEN-AI-Mistral7B\noutput_dir: ./qlora-out\n\nadapter: qlora\nlora_model_dir:\n\nsequence_len: 1024\nsample_packing: true\npad_to_sequence_len: true\n\nlora_r: 32\nlora_alpha: 16\nlora_dropout: 0.05\nlora_target_linear: true\nlora_fan_in_fan_out:\nlora_target_modules:\n  - gate_proj\n  - down_proj\n  - up_proj\n  - q_proj\n  - v_proj\n  - k_proj\n  - o_proj\n\nwandb_project: physigenai-mistral7b\nwandb_entity:\nwandb_watch:\nwandb_name:\nwandb_log_model:\n\ngradient_accumulation_steps: 4\nmicro_batch_size: 2\nnum_epochs: 3\noptimizer: adamw_bnb_8bit\nlr_scheduler: cosine\nlearning_rate: 0.0002\n\ntrain_on_inputs: false\ngroup_by_length: false\nbf16: false\nfp16: true\ntf32: false\n\ngradient_checkpointing: true\nearly_stopping_patience:\nresume_from_checkpoint:\nlocal_rank:\nlogging_steps: 1\nxformers_attention:\nflash_attention: false\neval_sample_packing: False\nwarmup_steps: 10\neval_steps: 20\nsave_steps: 20\ndebug:\ndeepspeed:\nweight_decay: 0.0\nfsdp:\nfsdp_config:\nspecial_tokens:\n  bos_token: \"<s>\"\n  eos_token: \"</s>\"\n  unk_token: \"<unk>\"\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip install bitsandbytes\n!pip install huggingface_hub\n!pip install flash_attn\n!pip install git+https://github.com/huggingface/transformers.git\n!pip install git+https://github.com/huggingface/peft.git\n!pip install git+https://github.com/huggingface/accelerate.git","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:38:07.095241Z","iopub.execute_input":"2023-12-22T05:38:07.095569Z","iopub.status.idle":"2023-12-22T05:40:22.486403Z","shell.execute_reply.started":"2023-12-22T05:38:07.095539Z","shell.execute_reply":"2023-12-22T05:40:22.485232Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# from huggingface_hub import notebook_login\n\n# notebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T20:51:13.452566Z","iopub.execute_input":"2023-12-21T20:51:13.452880Z","iopub.status.idle":"2023-12-21T20:51:13.457239Z","shell.execute_reply.started":"2023-12-21T20:51:13.452851Z","shell.execute_reply":"2023-12-21T20:51:13.456336Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"!huggingface cli login --token \"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\"","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:37:27.722675Z","iopub.execute_input":"2023-12-21T21:37:27.722989Z","iopub.status.idle":"2023-12-21T21:37:28.674258Z","shell.execute_reply.started":"2023-12-21T21:37:27.722962Z","shell.execute_reply":"2023-12-21T21:37:28.673276Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/bin/bash: line 1: huggingface: command not found\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import interpreter_login\n\ninterpreter_login()","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:40:22.488727Z","iopub.execute_input":"2023-12-22T05:40:22.489041Z","iopub.status.idle":"2023-12-22T05:40:44.398762Z","shell.execute_reply.started":"2023-12-22T05:40:22.489011Z","shell.execute_reply":"2023-12-22T05:40:44.397843Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\n    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n\n    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Token:  ·····································\nAdd token as git credential? (Y/n)  y\n"},{"name":"stdout","text":"Token is valid (permission: write).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"%env WANDB_MODE=online","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:40:44.399797Z","iopub.execute_input":"2023-12-22T05:40:44.400109Z","iopub.status.idle":"2023-12-22T05:40:44.405422Z","shell.execute_reply.started":"2023-12-22T05:40:44.400082Z","shell.execute_reply":"2023-12-22T05:40:44.404543Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"env: WANDB_MODE=online\n","output_type":"stream"}]},{"cell_type":"code","source":"!wandb login \"f0089c56904c153a908823262c11ea54299c4770\"","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:40:44.406670Z","iopub.execute_input":"2023-12-22T05:40:44.407022Z","iopub.status.idle":"2023-12-22T05:40:47.879765Z","shell.execute_reply.started":"2023-12-22T05:40:44.406989Z","shell.execute_reply":"2023-12-22T05:40:47.878641Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"!accelerate launch -m axolotl.cli.train /kaggle/working/axolotl/examples/mistral/qlora.yml","metadata":{"execution":{"iopub.status.busy":"2023-12-22T05:40:47.881406Z","iopub.execute_input":"2023-12-22T05:40:47.882285Z","iopub.status.idle":"2023-12-22T06:09:47.007923Z","shell.execute_reply.started":"2023-12-22T05:40:47.882243Z","shell.execute_reply":"2023-12-22T06:09:47.006607Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c107WarningC1ENS_7variantIJNS0_11UserWarningENS0_18DeprecationWarningEEEERKNS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n  warnings.warn(\nconfig.json: 100%|█████████████████████████████| 624/624 [00:00<00:00, 3.97MB/s]\n[2023-12-22 05:41:16,909] [INFO] [axolotl.log_gpu_memory_usage:71] [PID:500] [RANK:1] GPU memory usage baseline: 0.000GB (+0.003GB misc)\u001b[39m\n[2023-12-22 05:41:16,956] [INFO] [axolotl.log_gpu_memory_usage:71] [PID:499] [RANK:0] GPU memory usage baseline: 0.000GB (+0.003GB misc)\u001b[39m\n                                 dP            dP   dP \n                                 88            88   88 \n      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n                                                       \n                                                       \n\n\u001b[33m[2023-12-22 05:41:16,976] [WARNING] [axolotl.scripts.check_accelerate_default_config:346] [PID:499] [RANK:0] accelerate config file found at /root/.cache/huggingface/accelerate/default_config.yaml. This can lead to unexpected errors\u001b[39m\n\u001b[33m[2023-12-22 05:41:16,979] [WARNING] [axolotl.scripts.check_accelerate_default_config:346] [PID:500] [RANK:1] accelerate config file found at /root/.cache/huggingface/accelerate/default_config.yaml. This can lead to unexpected errors\u001b[39m\ntokenizer_config.json: 100%|███████████████| 1.60k/1.60k [00:00<00:00, 11.2MB/s]\ntokenizer.model: 100%|███████████████████████| 493k/493k [00:00<00:00, 9.51MB/s]\nadded_tokens.json: 100%|██████████████████████| 51.0/51.0 [00:00<00:00, 485kB/s]\nspecial_tokens_map.json: 100%|██████████████████| 101/101 [00:00<00:00, 679kB/s]\n[2023-12-22 05:41:17,980] [DEBUG] [axolotl.load_tokenizer:167] [PID:499] [RANK:0] EOS: 2 / </s>\u001b[39m\n[2023-12-22 05:41:17,981] [DEBUG] [axolotl.load_tokenizer:168] [PID:499] [RANK:0] BOS: 1 / <s>\u001b[39m\n[2023-12-22 05:41:17,981] [DEBUG] [axolotl.load_tokenizer:169] [PID:499] [RANK:0] PAD: 2 / </s>\u001b[39m\n[2023-12-22 05:41:17,981] [DEBUG] [axolotl.load_tokenizer:170] [PID:499] [RANK:0] UNK: 0 / <unk>\u001b[39m\n[2023-12-22 05:41:17,981] [INFO] [axolotl.load_tokenized_prepared_datasets:147] [PID:499] [RANK:0] Unable to find prepared dataset in last_run_prepared/5a9f9c1a3602cfc4e302f6facf232bb2\u001b[39m\n[2023-12-22 05:41:17,981] [INFO] [axolotl.load_tokenized_prepared_datasets:148] [PID:499] [RANK:0] Loading raw datasets...\u001b[39m\n[2023-12-22 05:41:17,982] [INFO] [axolotl.load_tokenized_prepared_datasets:153] [PID:499] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n[2023-12-22 05:41:17,985] [DEBUG] [axolotl.load_tokenizer:167] [PID:500] [RANK:1] EOS: 2 / </s>\u001b[39m\n[2023-12-22 05:41:17,985] [DEBUG] [axolotl.load_tokenizer:168] [PID:500] [RANK:1] BOS: 1 / <s>\u001b[39m\n[2023-12-22 05:41:17,985] [DEBUG] [axolotl.load_tokenizer:169] [PID:500] [RANK:1] PAD: 2 / </s>\u001b[39m\n[2023-12-22 05:41:17,985] [DEBUG] [axolotl.load_tokenizer:170] [PID:500] [RANK:1] UNK: 0 / <unk>\u001b[39m\nDownloading readme: 100%|███████████████████████| 433/433 [00:00<00:00, 378kB/s]\nDownloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\nDownloading data:   0%|                              | 0.00/264k [00:00<?, ?B/s]\u001b[A\nDownloading data: 100%|██████████████████████| 264k/264k [00:00<00:00, 1.26MB/s]\u001b[A\nDownloading data files: 100%|█████████████████████| 1/1 [00:00<00:00,  4.73it/s]\nExtracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1404.66it/s]\nGenerating train split: 100%|███████| 785/785 [00:00<00:00, 16908.52 examples/s]\nMap (num_proc=4): 100%|███████████████| 785/785 [00:01<00:00, 593.59 examples/s]\n[2023-12-22 05:41:21,354] [INFO] [axolotl.load_tokenized_prepared_datasets:362] [PID:499] [RANK:0] merging datasets\u001b[39m\n[2023-12-22 05:41:21,357] [INFO] [axolotl.load_tokenized_prepared_datasets:369] [PID:499] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/5a9f9c1a3602cfc4e302f6facf232bb2\u001b[39m\nSaving the dataset (1/1 shards): 100%|█| 785/785 [00:00<00:00, 61517.29 examples\n[2023-12-22 05:41:24,374] [INFO] [axolotl.load_tokenized_prepared_datasets:143] [PID:500] [RANK:1] Loading prepared dataset from disk at last_run_prepared/5a9f9c1a3602cfc4e302f6facf232bb2...\u001b[39m\n[2023-12-22 05:41:24,378] [INFO] [axolotl.load_tokenized_prepared_datasets:145] [PID:500] [RANK:1] Prepared dataset loaded from disk...\u001b[39m\nFilter (num_proc=4): 100%|███████████| 777/777 [00:00<00:00, 1605.33 examples/s]\nFilter (num_proc=4): 100%|█████████████████| 8/8 [00:00<00:00, 35.23 examples/s]\nMap (num_proc=4): 100%|██████████████| 776/776 [00:00<00:00, 1657.99 examples/s]\n[2023-12-22 05:41:26,205] [DEBUG] [axolotl.log:61] [PID:499] [RANK:0] total_num_tokens: 253528\u001b[39m\n[2023-12-22 05:41:26,221] [DEBUG] [axolotl.log:61] [PID:499] [RANK:0] `total_supervised_tokens: 179165`\u001b[39m\nFilter (num_proc=4): 100%|███████████| 777/777 [00:00<00:00, 1578.31 examples/s]\nFilter (num_proc=4): 100%|█████████████████| 8/8 [00:00<00:00, 34.03 examples/s]\nMap (num_proc=4): 100%|██████████████| 776/776 [00:00<00:00, 1882.37 examples/s]\n[2023-12-22 05:41:32,676] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:499] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:41:32,676] [DEBUG] [axolotl.log:61] [PID:499] [RANK:0] data_loader_len: 121\u001b[39m\n[2023-12-22 05:41:34,041] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:500] [RANK:1] packing_efficiency_estimate: 1.0 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:41:34,049] [INFO] [axolotl.log:61] [PID:499] [RANK:0] sample_packing_eff_est across ranks: [0.8970504999160767, 0.8905969262123108]\u001b[39m\n[2023-12-22 05:41:34,057] [DEBUG] [axolotl.log:61] [PID:499] [RANK:0] sample_packing_eff_est: 0.9\u001b[39m\n[2023-12-22 05:41:34,057] [DEBUG] [axolotl.log:61] [PID:499] [RANK:0] total_num_steps: 181\u001b[39m\n[2023-12-22 05:41:34,058] [DEBUG] [axolotl.train.log:61] [PID:499] [RANK:0] loading tokenizer... teknium/OpenHermes-2.5-Mistral-7B\u001b[39m\n[2023-12-22 05:41:34,458] [DEBUG] [axolotl.load_tokenizer:167] [PID:499] [RANK:0] EOS: 2 / </s>\u001b[39m\n[2023-12-22 05:41:34,459] [DEBUG] [axolotl.load_tokenizer:168] [PID:499] [RANK:0] BOS: 1 / <s>\u001b[39m\n[2023-12-22 05:41:34,459] [DEBUG] [axolotl.load_tokenizer:169] [PID:499] [RANK:0] PAD: 2 / </s>\u001b[39m\n[2023-12-22 05:41:34,459] [DEBUG] [axolotl.load_tokenizer:170] [PID:499] [RANK:0] UNK: 0 / <unk>\u001b[39m\n[2023-12-22 05:41:34,459] [DEBUG] [axolotl.train.log:61] [PID:499] [RANK:0] loading model and peft_config...\u001b[39m\n[2023-12-22 05:41:34,473] [DEBUG] [axolotl.load_tokenizer:167] [PID:500] [RANK:1] EOS: 2 / </s>\u001b[39m\n[2023-12-22 05:41:34,474] [DEBUG] [axolotl.load_tokenizer:168] [PID:500] [RANK:1] BOS: 1 / <s>\u001b[39m\n[2023-12-22 05:41:34,474] [DEBUG] [axolotl.load_tokenizer:169] [PID:500] [RANK:1] PAD: 2 / </s>\u001b[39m\n[2023-12-22 05:41:34,474] [DEBUG] [axolotl.load_tokenizer:170] [PID:500] [RANK:1] UNK: 0 / <unk>\u001b[39m\nmodel.safetensors.index.json: 100%|████████| 25.1k/25.1k [00:00<00:00, 26.7MB/s]\nDownloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]\nmodel-00001-of-00002.safetensors:   0%|             | 0.00/9.94G [00:00<?, ?B/s]\u001b[A\nmodel-00001-of-00002.safetensors:   0%|    | 10.5M/9.94G [00:00<04:29, 36.9MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   0%|     | 41.9M/9.94G [00:00<01:26, 115MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   1%|     | 73.4M/9.94G [00:00<01:01, 159MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   1%|      | 105M/9.94G [00:00<00:53, 184MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   1%|      | 136M/9.94G [00:00<00:48, 202MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   2%|      | 168M/9.94G [00:00<00:45, 215MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   2%|      | 199M/9.94G [00:01<00:44, 220MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   2%|▏     | 231M/9.94G [00:01<00:42, 227MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   3%|▏     | 262M/9.94G [00:01<00:42, 227MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   3%|▏     | 294M/9.94G [00:01<00:41, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   3%|▏     | 325M/9.94G [00:01<00:41, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   4%|▏     | 357M/9.94G [00:01<00:40, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   4%|▏     | 388M/9.94G [00:01<00:40, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   4%|▎     | 419M/9.94G [00:02<00:40, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   5%|▎     | 451M/9.94G [00:02<00:39, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   5%|▎     | 482M/9.94G [00:02<00:39, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   5%|▎     | 514M/9.94G [00:02<00:39, 240MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   5%|▎     | 545M/9.94G [00:02<00:39, 241MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   6%|▎     | 577M/9.94G [00:02<00:39, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   6%|▎     | 608M/9.94G [00:02<00:39, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   6%|▍     | 640M/9.94G [00:02<00:39, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   7%|▍     | 671M/9.94G [00:03<00:39, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   7%|▍     | 703M/9.94G [00:03<00:40, 230MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   7%|▍     | 734M/9.94G [00:03<00:39, 231MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   8%|▍     | 765M/9.94G [00:03<00:39, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   8%|▍     | 797M/9.94G [00:03<00:39, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   8%|▍     | 828M/9.94G [00:03<00:38, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   9%|▌     | 860M/9.94G [00:03<00:38, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   9%|▌     | 891M/9.94G [00:04<00:38, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:   9%|▌     | 923M/9.94G [00:04<00:37, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  10%|▌     | 954M/9.94G [00:04<00:37, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  10%|▌     | 986M/9.94G [00:04<00:38, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  10%|▌    | 1.02G/9.94G [00:04<00:38, 229MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  11%|▌    | 1.05G/9.94G [00:04<00:38, 230MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  11%|▌    | 1.08G/9.94G [00:04<00:38, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  11%|▌    | 1.11G/9.94G [00:04<00:37, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  11%|▌    | 1.14G/9.94G [00:05<00:37, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  12%|▌    | 1.17G/9.94G [00:05<00:36, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  12%|▌    | 1.21G/9.94G [00:05<00:37, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  12%|▌    | 1.24G/9.94G [00:05<00:36, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  13%|▋    | 1.27G/9.94G [00:05<00:36, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  13%|▋    | 1.30G/9.94G [00:05<00:36, 240MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  13%|▋    | 1.33G/9.94G [00:05<00:35, 242MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  14%|▋    | 1.36G/9.94G [00:06<00:35, 242MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  14%|▋    | 1.39G/9.94G [00:06<00:35, 242MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  14%|▋    | 1.43G/9.94G [00:06<00:35, 240MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  15%|▋    | 1.46G/9.94G [00:06<00:35, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  15%|▋    | 1.49G/9.94G [00:06<00:35, 240MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  15%|▊    | 1.52G/9.94G [00:06<00:35, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  16%|▊    | 1.55G/9.94G [00:06<00:35, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  16%|▊    | 1.58G/9.94G [00:06<00:34, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  16%|▊    | 1.61G/9.94G [00:07<00:34, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  17%|▊    | 1.65G/9.94G [00:07<00:35, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  17%|▊    | 1.68G/9.94G [00:07<00:35, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  17%|▊    | 1.71G/9.94G [00:07<00:35, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  18%|▉    | 1.74G/9.94G [00:07<00:35, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  18%|▉    | 1.77G/9.94G [00:07<00:34, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  18%|▉    | 1.80G/9.94G [00:07<00:34, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  18%|▉    | 1.84G/9.94G [00:07<00:34, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  19%|▉    | 1.87G/9.94G [00:08<00:33, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  19%|▉    | 1.90G/9.94G [00:08<00:33, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  19%|▉    | 1.93G/9.94G [00:08<00:33, 241MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  20%|▉    | 1.96G/9.94G [00:08<00:33, 241MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  20%|█    | 1.99G/9.94G [00:08<00:33, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  20%|█    | 2.02G/9.94G [00:08<00:33, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  21%|█    | 2.06G/9.94G [00:08<00:32, 240MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  21%|█    | 2.09G/9.94G [00:09<00:33, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  21%|█    | 2.12G/9.94G [00:09<00:33, 231MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  22%|█    | 2.15G/9.94G [00:09<00:34, 229MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  22%|█    | 2.18G/9.94G [00:09<00:33, 229MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  22%|█    | 2.21G/9.94G [00:09<00:33, 231MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  23%|█▏   | 2.24G/9.94G [00:09<00:32, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  23%|█▏   | 2.28G/9.94G [00:09<00:34, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  23%|█▏   | 2.31G/9.94G [00:10<00:34, 221MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  24%|█▏   | 2.34G/9.94G [00:10<00:34, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  24%|█▏   | 2.37G/9.94G [00:10<00:34, 222MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  24%|█▏   | 2.40G/9.94G [00:10<00:34, 221MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  24%|█▏   | 2.43G/9.94G [00:10<00:33, 222MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  25%|█▏   | 2.46G/9.94G [00:10<00:33, 223MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  25%|█▎   | 2.50G/9.94G [00:10<00:33, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  25%|█▎   | 2.53G/9.94G [00:11<00:33, 223MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  26%|█▎   | 2.56G/9.94G [00:11<00:33, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  26%|█▎   | 2.59G/9.94G [00:11<00:32, 225MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  26%|█▎   | 2.62G/9.94G [00:11<00:32, 226MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  27%|█▎   | 2.65G/9.94G [00:11<00:32, 225MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  27%|█▎   | 2.68G/9.94G [00:11<00:32, 226MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  27%|█▎   | 2.72G/9.94G [00:11<00:32, 225MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  28%|█▍   | 2.75G/9.94G [00:12<00:32, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  28%|█▍   | 2.78G/9.94G [00:12<00:32, 221MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  28%|█▍   | 2.81G/9.94G [00:12<00:32, 220MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  29%|█▍   | 2.84G/9.94G [00:12<00:32, 221MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  29%|█▍   | 2.87G/9.94G [00:12<00:32, 220MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  29%|█▍   | 2.90G/9.94G [00:12<00:32, 220MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  30%|█▍   | 2.94G/9.94G [00:12<00:31, 220MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  30%|█▍   | 2.97G/9.94G [00:13<00:32, 217MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  30%|█▌   | 3.00G/9.94G [00:13<00:31, 218MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  30%|█▌   | 3.03G/9.94G [00:13<00:31, 219MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  31%|█▌   | 3.06G/9.94G [00:13<00:31, 220MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  31%|█▌   | 3.09G/9.94G [00:13<00:31, 219MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  31%|█▌   | 3.12G/9.94G [00:13<00:30, 220MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  32%|█▌   | 3.16G/9.94G [00:13<00:30, 219MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  32%|█▌   | 3.19G/9.94G [00:14<00:30, 220MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  32%|█▌   | 3.22G/9.94G [00:14<00:30, 222MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  33%|█▋   | 3.25G/9.94G [00:14<00:30, 219MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  33%|█▋   | 3.28G/9.94G [00:14<00:29, 226MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  33%|█▋   | 3.31G/9.94G [00:14<00:29, 229MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  34%|█▋   | 3.34G/9.94G [00:14<00:28, 231MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  34%|█▋   | 3.38G/9.94G [00:14<00:28, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  34%|█▋   | 3.41G/9.94G [00:14<00:28, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  35%|█▋   | 3.44G/9.94G [00:15<00:27, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  35%|█▋   | 3.47G/9.94G [00:15<00:31, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  35%|█▊   | 3.50G/9.94G [00:15<00:30, 211MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  36%|█▊   | 3.53G/9.94G [00:15<00:29, 215MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  36%|█▊   | 3.57G/9.94G [00:15<00:29, 220MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  36%|█▊   | 3.60G/9.94G [00:15<00:28, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  36%|█▊   | 3.63G/9.94G [00:15<00:27, 226MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  37%|█▊   | 3.66G/9.94G [00:16<00:27, 228MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  37%|█▊   | 3.69G/9.94G [00:16<00:27, 231MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  37%|█▊   | 3.72G/9.94G [00:16<00:26, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  38%|█▉   | 3.75G/9.94G [00:16<00:26, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  38%|█▉   | 3.79G/9.94G [00:16<00:25, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  38%|█▉   | 3.82G/9.94G [00:16<00:25, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  39%|█▉   | 3.85G/9.94G [00:16<00:25, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  39%|█▉   | 3.88G/9.94G [00:17<00:25, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  39%|█▉   | 3.91G/9.94G [00:17<00:25, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  40%|█▉   | 3.94G/9.94G [00:17<00:25, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  40%|█▉   | 3.97G/9.94G [00:17<00:25, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  40%|██   | 4.01G/9.94G [00:17<00:25, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  41%|██   | 4.04G/9.94G [00:17<00:24, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  41%|██   | 4.07G/9.94G [00:17<00:24, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  41%|██   | 4.10G/9.94G [00:17<00:24, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  42%|██   | 4.13G/9.94G [00:18<00:24, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  42%|██   | 4.16G/9.94G [00:18<00:24, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  42%|██   | 4.19G/9.94G [00:18<00:24, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  42%|██   | 4.23G/9.94G [00:18<00:24, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  43%|██▏  | 4.26G/9.94G [00:18<00:24, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  43%|██▏  | 4.29G/9.94G [00:18<00:24, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  43%|██▏  | 4.32G/9.94G [00:18<00:24, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  44%|██▏  | 4.35G/9.94G [00:19<00:23, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  44%|██▏  | 4.38G/9.94G [00:19<00:23, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  44%|██▏  | 4.41G/9.94G [00:19<00:23, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  45%|██▏  | 4.45G/9.94G [00:19<00:34, 161MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  45%|██▎  | 4.48G/9.94G [00:19<00:30, 177MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  45%|██▎  | 4.51G/9.94G [00:19<00:28, 192MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  46%|██▎  | 4.54G/9.94G [00:20<00:26, 204MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  46%|██▎  | 4.57G/9.94G [00:20<00:25, 211MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  46%|██▎  | 4.60G/9.94G [00:20<00:24, 218MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  47%|██▎  | 4.63G/9.94G [00:20<00:23, 225MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  47%|██▎  | 4.67G/9.94G [00:20<00:23, 226MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  47%|██▎  | 4.70G/9.94G [00:20<00:22, 230MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  48%|██▍  | 4.73G/9.94G [00:20<00:22, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  48%|██▍  | 4.76G/9.94G [00:20<00:22, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  48%|██▍  | 4.79G/9.94G [00:21<00:22, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  49%|██▍  | 4.82G/9.94G [00:21<00:21, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  49%|██▍  | 4.85G/9.94G [00:21<00:21, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  49%|██▍  | 4.89G/9.94G [00:21<00:21, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  49%|██▍  | 4.92G/9.94G [00:21<00:21, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  50%|██▍  | 4.95G/9.94G [00:21<00:20, 240MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  50%|██▌  | 4.98G/9.94G [00:21<00:20, 241MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  50%|██▌  | 5.01G/9.94G [00:22<00:20, 241MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  51%|██▌  | 5.04G/9.94G [00:22<00:20, 240MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  51%|██▌  | 5.08G/9.94G [00:22<00:20, 241MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  51%|██▌  | 5.11G/9.94G [00:22<00:20, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  52%|██▌  | 5.14G/9.94G [00:22<00:20, 238MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  52%|██▌  | 5.17G/9.94G [00:22<00:20, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  52%|██▌  | 5.20G/9.94G [00:22<00:20, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  53%|██▋  | 5.23G/9.94G [00:22<00:20, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  53%|██▋  | 5.26G/9.94G [00:23<00:20, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  53%|██▋  | 5.30G/9.94G [00:23<00:19, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  54%|██▋  | 5.33G/9.94G [00:23<00:20, 230MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  54%|██▋  | 5.36G/9.94G [00:23<00:19, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  54%|██▋  | 5.39G/9.94G [00:23<00:19, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  55%|██▋  | 5.42G/9.94G [00:23<00:19, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  55%|██▋  | 5.45G/9.94G [00:23<00:19, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  55%|██▊  | 5.48G/9.94G [00:24<00:19, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  55%|██▊  | 5.52G/9.94G [00:24<00:18, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  56%|██▊  | 5.55G/9.94G [00:24<00:18, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  56%|██▊  | 5.58G/9.94G [00:24<00:18, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  56%|██▊  | 5.61G/9.94G [00:24<00:18, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  57%|██▊  | 5.64G/9.94G [00:24<00:18, 231MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  57%|██▊  | 5.67G/9.94G [00:24<00:18, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  57%|██▊  | 5.70G/9.94G [00:24<00:18, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  58%|██▉  | 5.74G/9.94G [00:25<00:18, 228MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  58%|██▉  | 5.77G/9.94G [00:25<00:18, 221MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  58%|██▉  | 5.80G/9.94G [00:25<00:20, 198MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  59%|██▉  | 5.82G/9.94G [00:25<00:23, 177MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  59%|██▉  | 5.84G/9.94G [00:25<00:23, 172MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  59%|██▉  | 5.86G/9.94G [00:25<00:22, 178MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  59%|██▉  | 5.89G/9.94G [00:26<00:21, 190MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  59%|██▉  | 5.91G/9.94G [00:26<00:20, 195MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  60%|██▉  | 5.93G/9.94G [00:26<00:20, 198MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  60%|███  | 5.97G/9.94G [00:26<00:19, 203MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  60%|███  | 6.00G/9.94G [00:26<00:19, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  61%|███  | 6.03G/9.94G [00:26<00:18, 210MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  61%|███  | 6.06G/9.94G [00:26<00:18, 215MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  61%|███  | 6.09G/9.94G [00:26<00:17, 215MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  62%|███  | 6.12G/9.94G [00:27<00:17, 216MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  62%|███  | 6.16G/9.94G [00:27<00:17, 219MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  62%|███  | 6.19G/9.94G [00:27<00:17, 220MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  63%|███▏ | 6.22G/9.94G [00:27<00:16, 219MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  63%|███▏ | 6.25G/9.94G [00:27<00:16, 221MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  63%|███▏ | 6.28G/9.94G [00:27<00:16, 222MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  63%|███▏ | 6.31G/9.94G [00:27<00:16, 222MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  64%|███▏ | 6.34G/9.94G [00:28<00:16, 223MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  64%|███▏ | 6.38G/9.94G [00:28<00:15, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  64%|███▏ | 6.41G/9.94G [00:28<00:15, 222MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  65%|███▏ | 6.44G/9.94G [00:28<00:15, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  65%|███▎ | 6.47G/9.94G [00:28<00:15, 223MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  65%|███▎ | 6.50G/9.94G [00:28<00:15, 226MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  66%|███▎ | 6.53G/9.94G [00:28<00:15, 227MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  66%|███▎ | 6.56G/9.94G [00:29<00:14, 226MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  66%|███▎ | 6.60G/9.94G [00:29<00:14, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  67%|███▎ | 6.63G/9.94G [00:29<00:14, 225MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  67%|███▎ | 6.66G/9.94G [00:29<00:14, 226MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  67%|███▎ | 6.69G/9.94G [00:29<00:14, 222MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  68%|███▍ | 6.72G/9.94G [00:29<00:14, 225MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  68%|███▍ | 6.75G/9.94G [00:29<00:14, 226MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  68%|███▍ | 6.78G/9.94G [00:30<00:14, 226MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  69%|███▍ | 6.82G/9.94G [00:30<00:13, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  69%|███▍ | 6.85G/9.94G [00:30<00:14, 219MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  69%|███▍ | 6.88G/9.94G [00:30<00:13, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  69%|███▍ | 6.91G/9.94G [00:30<00:13, 225MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  70%|███▍ | 6.94G/9.94G [00:30<00:13, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  70%|███▌ | 6.97G/9.94G [00:30<00:12, 229MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  70%|███▌ | 7.00G/9.94G [00:31<00:12, 231MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  71%|███▌ | 7.04G/9.94G [00:31<00:12, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  71%|███▌ | 7.07G/9.94G [00:31<00:12, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  71%|███▌ | 7.10G/9.94G [00:31<00:12, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  72%|███▌ | 7.13G/9.94G [00:31<00:12, 231MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  72%|███▌ | 7.16G/9.94G [00:31<00:12, 231MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  72%|███▌ | 7.19G/9.94G [00:31<00:11, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  73%|███▋ | 7.22G/9.94G [00:31<00:11, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  73%|███▋ | 7.26G/9.94G [00:32<00:11, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  73%|███▋ | 7.29G/9.94G [00:32<00:11, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  74%|███▋ | 7.32G/9.94G [00:32<00:11, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  74%|███▋ | 7.35G/9.94G [00:32<00:11, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  74%|███▋ | 7.38G/9.94G [00:32<00:10, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  75%|███▋ | 7.41G/9.94G [00:32<00:10, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  75%|███▋ | 7.44G/9.94G [00:32<00:10, 240MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  75%|███▊ | 7.48G/9.94G [00:33<00:10, 240MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  76%|███▊ | 7.51G/9.94G [00:33<00:10, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  76%|███▊ | 7.54G/9.94G [00:33<00:10, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  76%|███▊ | 7.57G/9.94G [00:33<00:09, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  76%|███▊ | 7.60G/9.94G [00:33<00:09, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  77%|███▊ | 7.63G/9.94G [00:33<00:09, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  77%|███▊ | 7.67G/9.94G [00:33<00:09, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  77%|███▊ | 7.70G/9.94G [00:33<00:09, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  78%|███▉ | 7.73G/9.94G [00:34<00:09, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  78%|███▉ | 7.76G/9.94G [00:34<00:09, 237MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  78%|███▉ | 7.79G/9.94G [00:34<00:08, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  79%|███▉ | 7.82G/9.94G [00:34<00:08, 239MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  79%|███▉ | 7.85G/9.94G [00:34<00:08, 240MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  79%|███▉ | 7.89G/9.94G [00:34<00:08, 241MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  80%|███▉ | 7.92G/9.94G [00:34<00:08, 242MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  80%|███▉ | 7.95G/9.94G [00:34<00:08, 243MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  80%|████ | 7.98G/9.94G [00:35<00:08, 241MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  81%|████ | 8.01G/9.94G [00:35<00:08, 241MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  81%|████ | 8.04G/9.94G [00:35<00:08, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  81%|████ | 8.07G/9.94G [00:35<00:07, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  82%|████ | 8.11G/9.94G [00:35<00:09, 197MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  82%|████ | 8.14G/9.94G [00:35<00:08, 205MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  82%|████ | 8.17G/9.94G [00:36<00:08, 213MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  82%|████ | 8.20G/9.94G [00:36<00:08, 199MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  83%|████▏| 8.22G/9.94G [00:36<00:08, 199MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  83%|████▏| 8.25G/9.94G [00:36<00:08, 209MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  83%|████▏| 8.28G/9.94G [00:36<00:07, 215MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  84%|████▏| 8.32G/9.94G [00:36<00:07, 222MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  84%|████▏| 8.35G/9.94G [00:36<00:07, 224MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  84%|████▏| 8.38G/9.94G [00:36<00:06, 230MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  85%|████▏| 8.41G/9.94G [00:37<00:06, 230MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  85%|████▏| 8.44G/9.94G [00:37<00:06, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  85%|████▎| 8.47G/9.94G [00:37<00:06, 228MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  86%|████▎| 8.50G/9.94G [00:37<00:06, 229MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  86%|████▎| 8.54G/9.94G [00:37<00:06, 231MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  86%|████▎| 8.57G/9.94G [00:37<00:05, 231MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  86%|████▎| 8.60G/9.94G [00:37<00:05, 229MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  87%|████▎| 8.63G/9.94G [00:38<00:05, 229MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  87%|████▎| 8.66G/9.94G [00:38<00:05, 230MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  87%|████▎| 8.69G/9.94G [00:38<00:05, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  88%|████▍| 8.72G/9.94G [00:38<00:05, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  88%|████▍| 8.76G/9.94G [00:38<00:05, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  88%|████▍| 8.79G/9.94G [00:38<00:04, 236MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  89%|████▍| 8.82G/9.94G [00:38<00:04, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  89%|████▍| 8.85G/9.94G [00:38<00:04, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  89%|████▍| 8.88G/9.94G [00:39<00:04, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  90%|████▍| 8.91G/9.94G [00:39<00:04, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  90%|████▍| 8.94G/9.94G [00:39<00:04, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  90%|████▌| 8.98G/9.94G [00:39<00:04, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  91%|████▌| 9.01G/9.94G [00:39<00:03, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  91%|████▌| 9.04G/9.94G [00:39<00:03, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  91%|████▌| 9.07G/9.94G [00:39<00:03, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  92%|████▌| 9.10G/9.94G [00:40<00:03, 235MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  92%|████▌| 9.13G/9.94G [00:40<00:03, 234MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  92%|████▌| 9.16G/9.94G [00:40<00:03, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  92%|████▌| 9.20G/9.94G [00:40<00:03, 233MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  93%|████▋| 9.23G/9.94G [00:40<00:03, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  93%|████▋| 9.26G/9.94G [00:40<00:03, 217MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  93%|████▋| 9.29G/9.94G [00:40<00:02, 223MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  94%|████▋| 9.32G/9.94G [00:41<00:02, 229MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  94%|████▋| 9.35G/9.94G [00:41<00:02, 232MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  94%|████▋| 9.38G/9.94G [00:41<00:02, 230MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  95%|████▋| 9.42G/9.94G [00:41<00:02, 228MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  95%|████▊| 9.45G/9.94G [00:41<00:02, 227MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  95%|████▊| 9.48G/9.94G [00:41<00:02, 178MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  96%|████▊| 9.50G/9.94G [00:42<00:02, 156MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  96%|████▊| 9.52G/9.94G [00:42<00:02, 141MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  96%|████▊| 9.54G/9.94G [00:42<00:02, 145MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  96%|████▊| 9.56G/9.94G [00:42<00:02, 158MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  96%|████▊| 9.59G/9.94G [00:42<00:01, 177MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  97%|████▊| 9.63G/9.94G [00:42<00:01, 189MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  97%|████▊| 9.66G/9.94G [00:42<00:01, 199MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  97%|████▊| 9.69G/9.94G [00:43<00:01, 207MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  98%|████▉| 9.72G/9.94G [00:43<00:01, 209MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  98%|████▉| 9.75G/9.94G [00:43<00:00, 211MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  98%|████▉| 9.78G/9.94G [00:43<00:00, 215MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  99%|████▉| 9.81G/9.94G [00:43<00:00, 214MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  99%|████▉| 9.85G/9.94G [00:43<00:00, 213MB/s]\u001b[A\nmodel-00001-of-00002.safetensors:  99%|████▉| 9.88G/9.94G [00:43<00:00, 215MB/s]\u001b[A\nmodel-00001-of-00002.safetensors: 100%|████▉| 9.91G/9.94G [00:44<00:00, 215MB/s]\u001b[A\nmodel-00001-of-00002.safetensors: 100%|█████| 9.94G/9.94G [00:44<00:00, 225MB/s]\u001b[A\nDownloading shards:  50%|████████████▌            | 1/2 [00:44<00:44, 44.33s/it]\nmodel-00002-of-00002.safetensors:   0%|             | 0.00/4.54G [00:00<?, ?B/s]\u001b[A\nmodel-00002-of-00002.safetensors:   1%|     | 31.5M/4.54G [00:00<00:18, 239MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   1%|     | 62.9M/4.54G [00:00<00:19, 231MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   2%|     | 94.4M/4.54G [00:00<00:20, 222MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   3%|▏     | 126M/4.54G [00:00<00:19, 221MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   3%|▏     | 157M/4.54G [00:00<00:19, 222MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   4%|▏     | 189M/4.54G [00:00<00:19, 221MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   5%|▎     | 220M/4.54G [00:00<00:19, 220MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   6%|▎     | 252M/4.54G [00:01<00:19, 220MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   6%|▎     | 283M/4.54G [00:01<00:19, 218MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   7%|▎    | 315M/4.54G [00:03<01:44, 40.4MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   7%|▎    | 336M/4.54G [00:03<01:25, 49.0MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   8%|▍    | 367M/4.54G [00:03<01:02, 66.3MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   9%|▍    | 398M/4.54G [00:03<00:48, 86.2MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:   9%|▌     | 430M/4.54G [00:03<00:38, 108MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  10%|▌     | 461M/4.54G [00:04<00:31, 129MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  11%|▋     | 493M/4.54G [00:04<00:27, 150MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  12%|▋     | 524M/4.54G [00:04<00:23, 169MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  12%|▋     | 556M/4.54G [00:04<00:21, 186MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  13%|▊     | 587M/4.54G [00:04<00:19, 200MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  14%|▊     | 619M/4.54G [00:04<00:18, 212MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  14%|▊     | 650M/4.54G [00:04<00:17, 220MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  15%|▉     | 682M/4.54G [00:05<00:17, 226MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  16%|▉     | 713M/4.54G [00:05<00:16, 231MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  16%|▉     | 744M/4.54G [00:05<00:16, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  17%|█     | 776M/4.54G [00:05<00:16, 232MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  18%|█     | 807M/4.54G [00:05<00:15, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  18%|█     | 839M/4.54G [00:05<00:15, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  19%|█▏    | 870M/4.54G [00:05<00:15, 236MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  20%|█▏    | 902M/4.54G [00:05<00:15, 237MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  21%|█▏    | 933M/4.54G [00:06<00:15, 239MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  21%|█▎    | 965M/4.54G [00:06<00:14, 239MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  22%|█▎    | 996M/4.54G [00:06<00:14, 241MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  23%|█▏   | 1.03G/4.54G [00:06<00:14, 241MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  23%|█▏   | 1.06G/4.54G [00:06<00:14, 241MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  24%|█▏   | 1.09G/4.54G [00:06<00:14, 240MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  25%|█▏   | 1.12G/4.54G [00:06<00:14, 239MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  25%|█▎   | 1.15G/4.54G [00:07<00:14, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  26%|█▎   | 1.18G/4.54G [00:07<00:14, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  27%|█▎   | 1.22G/4.54G [00:07<00:14, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  27%|█▎   | 1.25G/4.54G [00:07<00:13, 236MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  28%|█▍   | 1.28G/4.54G [00:07<00:13, 237MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  29%|█▍   | 1.31G/4.54G [00:07<00:13, 237MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  30%|█▍   | 1.34G/4.54G [00:07<00:13, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  30%|█▌   | 1.37G/4.54G [00:07<00:13, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  31%|█▌   | 1.41G/4.54G [00:08<00:13, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  32%|█▌   | 1.44G/4.54G [00:08<00:13, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  32%|█▌   | 1.47G/4.54G [00:08<00:13, 236MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  33%|█▋   | 1.50G/4.54G [00:08<00:12, 237MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  34%|█▋   | 1.53G/4.54G [00:08<00:12, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  34%|█▋   | 1.56G/4.54G [00:08<00:12, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  35%|█▊   | 1.59G/4.54G [00:08<00:12, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  36%|█▊   | 1.63G/4.54G [00:09<00:12, 232MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  36%|█▊   | 1.66G/4.54G [00:09<00:12, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  37%|█▊   | 1.69G/4.54G [00:09<00:12, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  38%|█▉   | 1.72G/4.54G [00:09<00:12, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  39%|█▉   | 1.75G/4.54G [00:09<00:11, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  39%|█▉   | 1.78G/4.54G [00:09<00:11, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  40%|█▉   | 1.81G/4.54G [00:09<00:11, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  41%|██   | 1.85G/4.54G [00:09<00:11, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  41%|██   | 1.88G/4.54G [00:10<00:11, 236MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  42%|██   | 1.91G/4.54G [00:10<00:11, 237MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  43%|██▏  | 1.94G/4.54G [00:10<00:11, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  43%|█▋  | 1.97G/4.54G [00:12<01:08, 37.3MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  44%|█▊  | 1.99G/4.54G [00:12<00:56, 45.1MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  44%|█▊  | 2.01G/4.54G [00:13<00:45, 55.4MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  45%|█▊  | 2.03G/4.54G [00:13<00:36, 68.2MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  45%|█▊  | 2.07G/4.54G [00:13<00:27, 90.0MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  46%|██▎  | 2.10G/4.54G [00:13<00:21, 112MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  47%|██▎  | 2.13G/4.54G [00:13<00:18, 133MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  48%|██▍  | 2.16G/4.54G [00:13<00:15, 152MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  48%|██▍  | 2.19G/4.54G [00:13<00:13, 168MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  49%|██▍  | 2.22G/4.54G [00:14<00:12, 182MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  50%|██▍  | 2.25G/4.54G [00:14<00:11, 193MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  50%|██▌  | 2.29G/4.54G [00:14<00:11, 200MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  51%|██▌  | 2.32G/4.54G [00:14<00:10, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  52%|██▌  | 2.35G/4.54G [00:14<00:10, 211MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  52%|██▌  | 2.38G/4.54G [00:14<00:10, 215MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  53%|██▋  | 2.41G/4.54G [00:14<00:09, 219MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  54%|██▋  | 2.44G/4.54G [00:15<00:09, 222MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  55%|██▋  | 2.47G/4.54G [00:15<00:09, 224MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  55%|██▊  | 2.51G/4.54G [00:15<00:09, 222MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  56%|██▊  | 2.54G/4.54G [00:15<00:08, 225MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  57%|██▊  | 2.57G/4.54G [00:15<00:08, 229MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  57%|██▊  | 2.60G/4.54G [00:15<00:08, 232MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  58%|██▉  | 2.63G/4.54G [00:15<00:08, 232MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  59%|██▉  | 2.66G/4.54G [00:15<00:08, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  59%|██▉  | 2.69G/4.54G [00:16<00:07, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  60%|███  | 2.73G/4.54G [00:16<00:07, 236MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  61%|███  | 2.76G/4.54G [00:16<00:11, 160MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  61%|███  | 2.79G/4.54G [00:16<00:09, 175MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  62%|███  | 2.82G/4.54G [00:16<00:09, 188MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  63%|███▏ | 2.85G/4.54G [00:17<00:08, 199MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  64%|███▏ | 2.88G/4.54G [00:17<00:08, 206MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  64%|███▏ | 2.92G/4.54G [00:17<00:07, 214MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  65%|███▏ | 2.95G/4.54G [00:17<00:07, 220MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  66%|███▎ | 2.98G/4.54G [00:17<00:07, 223MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  66%|███▎ | 3.01G/4.54G [00:17<00:06, 226MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  67%|███▎ | 3.04G/4.54G [00:17<00:06, 229MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  68%|███▍ | 3.07G/4.54G [00:17<00:06, 228MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  68%|███▍ | 3.10G/4.54G [00:18<00:06, 228MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  69%|███▍ | 3.14G/4.54G [00:18<00:06, 229MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  70%|███▍ | 3.17G/4.54G [00:18<00:05, 230MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  70%|███▌ | 3.20G/4.54G [00:18<00:05, 231MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  71%|███▌ | 3.23G/4.54G [00:18<00:05, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  72%|███▌ | 3.26G/4.54G [00:18<00:05, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  73%|███▋ | 3.29G/4.54G [00:18<00:05, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  73%|███▋ | 3.32G/4.54G [00:19<00:05, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  74%|███▋ | 3.36G/4.54G [00:19<00:05, 230MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  75%|███▋ | 3.39G/4.54G [00:19<00:05, 231MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  75%|███▊ | 3.42G/4.54G [00:19<00:04, 231MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  76%|███▊ | 3.45G/4.54G [00:19<00:04, 230MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  77%|███▊ | 3.48G/4.54G [00:19<00:04, 231MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  77%|███▊ | 3.51G/4.54G [00:19<00:04, 232MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  78%|███▉ | 3.54G/4.54G [00:20<00:04, 230MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  79%|███▉ | 3.58G/4.54G [00:20<00:04, 232MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  79%|███▉ | 3.61G/4.54G [00:20<00:04, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  80%|████ | 3.64G/4.54G [00:20<00:03, 231MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  81%|████ | 3.67G/4.54G [00:20<00:03, 229MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  82%|████ | 3.70G/4.54G [00:20<00:03, 230MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  82%|████ | 3.73G/4.54G [00:20<00:03, 230MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  83%|████▏| 3.76G/4.54G [00:20<00:03, 231MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  84%|████▏| 3.80G/4.54G [00:21<00:03, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  84%|████▏| 3.83G/4.54G [00:21<00:03, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  85%|████▏| 3.86G/4.54G [00:21<00:02, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  86%|████▎| 3.89G/4.54G [00:21<00:02, 236MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  86%|████▎| 3.92G/4.54G [00:21<00:02, 236MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  87%|████▎| 3.95G/4.54G [00:21<00:02, 236MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  88%|████▍| 3.98G/4.54G [00:21<00:02, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  88%|████▍| 4.02G/4.54G [00:22<00:02, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  89%|████▍| 4.05G/4.54G [00:22<00:02, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  90%|████▍| 4.08G/4.54G [00:22<00:01, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  91%|████▌| 4.11G/4.54G [00:22<00:01, 235MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  91%|████▌| 4.14G/4.54G [00:22<00:01, 238MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  92%|████▌| 4.17G/4.54G [00:22<00:01, 239MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  93%|████▋| 4.20G/4.54G [00:22<00:01, 237MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  93%|████▋| 4.24G/4.54G [00:22<00:01, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  94%|████▋| 4.27G/4.54G [00:23<00:01, 216MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  95%|████▋| 4.30G/4.54G [00:23<00:01, 221MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  95%|████▊| 4.33G/4.54G [00:23<00:00, 226MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  96%|████▊| 4.36G/4.54G [00:23<00:00, 230MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  97%|████▊| 4.39G/4.54G [00:23<00:00, 233MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  97%|████▊| 4.42G/4.54G [00:23<00:00, 234MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  98%|████▉| 4.46G/4.54G [00:23<00:00, 236MB/s]\u001b[A\nmodel-00002-of-00002.safetensors:  99%|████▉| 4.49G/4.54G [00:24<00:00, 236MB/s]\u001b[A\nmodel-00002-of-00002.safetensors: 100%|█████| 4.54G/4.54G [00:24<00:00, 187MB/s]\u001b[A\nDownloading shards: 100%|█████████████████████████| 2/2 [01:08<00:00, 34.41s/it]\nDownloading shards: 100%|█████████████████████████| 2/2 [01:08<00:00, 34.41s/it]\nLoading checkpoint shards: 100%|██████████████████| 2/2 [01:19<00:00, 39.59s/it]\ngeneration_config.json: 100%|███████████████████| 120/120 [00:00<00:00, 710kB/s]\nLoading checkpoint shards: 100%|██████████████████| 2/2 [01:19<00:00, 39.78s/it]\n[2023-12-22 05:44:06,243] [INFO] [axolotl.log_gpu_memory_usage:71] [PID:500] [RANK:1] GPU memory usage after model load: 4.344GB (+0.136GB cache, +0.734GB misc)\u001b[39m\n[2023-12-22 05:44:06,257] [INFO] [axolotl.load_model:528] [PID:500] [RANK:1] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n[2023-12-22 05:44:06,270] [INFO] [axolotl.load_model:540] [PID:500] [RANK:1] converting modules to torch.float16 for flash attention\u001b[39m\n[2023-12-22 05:44:06,278] [INFO] [axolotl.load_lora:643] [PID:500] [RANK:1] found linear modules: ['up_proj', 'o_proj', 'gate_proj', 'q_proj', 'down_proj', 'v_proj', 'k_proj']\u001b[39m\n[2023-12-22 05:44:06,449] [INFO] [axolotl.log_gpu_memory_usage:71] [PID:499] [RANK:0] GPU memory usage after model load: 4.344GB (+0.136GB cache, +0.734GB misc)\u001b[39m\n[2023-12-22 05:44:06,455] [INFO] [axolotl.load_model:528] [PID:499] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n[2023-12-22 05:44:06,464] [INFO] [axolotl.load_model:540] [PID:499] [RANK:0] converting modules to torch.float16 for flash attention\u001b[39m\n[2023-12-22 05:44:06,470] [INFO] [axolotl.load_lora:643] [PID:499] [RANK:0] found linear modules: ['up_proj', 'gate_proj', 'down_proj', 'k_proj', 'o_proj', 'v_proj', 'q_proj']\u001b[39m\ntrainable params: 83,886,080 || all params: 7,325,634,560 || trainable%: 1.1451032577852205\n[2023-12-22 05:44:07,856] [INFO] [axolotl.log_gpu_memory_usage:71] [PID:499] [RANK:0] GPU memory usage after adapters: 4.673GB (+0.937GB cache, +0.734GB misc)\u001b[39m\ntrainable params: 83,886,080 || all params: 7,325,634,560 || trainable%: 1.1451032577852205\n[2023-12-22 05:44:07,948] [INFO] [axolotl.train.log:61] [PID:499] [RANK:0] Pre-saving adapter config to ./qlora-out\u001b[39m\n[2023-12-22 05:44:07,951] [INFO] [axolotl.train.log:61] [PID:499] [RANK:0] Starting trainer...\u001b[39m\n[2023-12-22 05:44:07,971] [INFO] [axolotl.log_gpu_memory_usage:71] [PID:500] [RANK:1] GPU memory usage after adapters: 4.673GB (+0.937GB cache, +0.734GB misc)\u001b[39m\n[2023-12-22 05:44:08,373] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:499] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:44:08,375] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:499] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:44:08,376] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:499] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:44:08,377] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:499] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:44:08,423] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:500] [RANK:1] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:44:08,424] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:500] [RANK:1] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:44:08,426] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:500] [RANK:1] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:44:08,427] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:500] [RANK:1] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:44:09,072] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:500] [RANK:1] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:44:09,074] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:500] [RANK:1] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msk4467\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/axolotl/wandb/run-20231222_054411-qjreapkd\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdry-sky-5\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/sk4467/physigenai-mistral7b\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/sk4467/physigenai-mistral7b/runs/qjreapkd\u001b[0m\n[2023-12-22 05:44:41,581] [INFO] [axolotl.callbacks.on_train_begin:567] [PID:499] [RANK:0] Axolotl config has been saved to WandB as an artifact.\u001b[39m\n  0%|                                                    | 0/48 [00:00<?, ?it/s][2023-12-22 05:44:41,584] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:499] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:44:41,587] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:499] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n{'loss': 3.0898, 'learning_rate': 2e-05, 'epoch': 0.06}                         \n  2%|▉                                           | 1/48 [00:31<24:25, 31.18s/it][2023-12-22 05:45:43,402] [INFO] [axolotl.callbacks.log_gpu_memory_usage:71] [PID:499] [RANK:0] GPU memory usage while training: 5.158GB (+6.227GB cache, +0.953GB misc)\u001b[39m\n  4%|█▊                                          | 2/48 [01:01<23:39, 30.86s/it][2023-12-22 05:45:43,413] [INFO] [axolotl.callbacks.log_gpu_memory_usage:71] [PID:500] [RANK:1] GPU memory usage while training: 5.158GB (+6.227GB cache, +0.953GB misc)\u001b[39m\n{'loss': 3.1742, 'learning_rate': 4e-05, 'epoch': 0.12}                         \n{'loss': 3.1399, 'learning_rate': 6e-05, 'epoch': 0.18}                         \n{'loss': 2.7938, 'learning_rate': 8e-05, 'epoch': 0.24}                         \n{'loss': 2.8238, 'learning_rate': 0.0001, 'epoch': 0.3}                         \n{'loss': 2.3703, 'learning_rate': 0.00012, 'epoch': 0.36}                       \n{'loss': 2.4328, 'learning_rate': 0.00014, 'epoch': 0.42}                       \n{'loss': 2.1542, 'learning_rate': 0.00016, 'epoch': 0.48}                       \n{'loss': 2.0476, 'learning_rate': 0.00018, 'epoch': 0.54}                       \n{'loss': 1.751, 'learning_rate': 0.0002, 'epoch': 0.6}                          \n{'loss': 1.5553, 'learning_rate': 0.000199658449300667, 'epoch': 0.66}          \n{'loss': 1.5978, 'learning_rate': 0.00019863613034027224, 'epoch': 0.72}        \n{'loss': 1.4718, 'learning_rate': 0.00019694002659393305, 'epoch': 0.78}        \n{'loss': 1.3456, 'learning_rate': 0.00019458172417006347, 'epoch': 0.84}        \n{'loss': 1.4195, 'learning_rate': 0.00019157733266550575, 'epoch': 0.9}         \n{'loss': 1.4273, 'learning_rate': 0.0001879473751206489, 'epoch': 0.96}         \n{'loss': 1.2187, 'learning_rate': 0.0001879473751206489, 'epoch': 1.01}         \n 35%|███████████████▏                           | 17/48 [08:43<15:53, 30.75s/it][2023-12-22 05:53:24,806] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:500] [RANK:1] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:53:24,808] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:500] [RANK:1] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:53:24,808] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:499] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 05:53:24,810] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:499] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n{'loss': 1.2279, 'learning_rate': 0.00018371664782625287, 'epoch': 1.06}        \n{'loss': 1.2843, 'learning_rate': 0.00017891405093963938, 'epoch': 1.12}        \n{'loss': 1.1523, 'learning_rate': 0.00017357239106731317, 'epoch': 1.18}        \n 42%|█████████████████▉                         | 20/48 [10:15<14:23, 30.84s/it]\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.8509848713874817, 'eval_runtime': 4.7941, 'eval_samples_per_second': 1.669, 'eval_steps_per_second': 0.417, 'epoch': 1.18}\n 42%|█████████████████▉                         | 20/48 [10:20<14:23, 30.84s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.29it/s]\u001b[A\n{'loss': 1.1585, 'learning_rate': 0.00016772815716257412, 'epoch': 1.24}        \u001b[A\n{'loss': 1.1007, 'learning_rate': 0.0001614212712689668, 'epoch': 1.3}          \n{'loss': 1.0605, 'learning_rate': 0.00015469481581224272, 'epoch': 1.36}        \n{'loss': 1.0631, 'learning_rate': 0.00014759473930370736, 'epoch': 1.42}        \n{'loss': 1.1284, 'learning_rate': 0.00014016954246529696, 'epoch': 1.48}        \n{'loss': 1.0558, 'learning_rate': 0.00013246994692046836, 'epoch': 1.54}        \n{'loss': 1.081, 'learning_rate': 0.00012454854871407994, 'epoch': 1.6}          \n{'loss': 1.0223, 'learning_rate': 0.00011645945902807341, 'epoch': 1.66}        \n{'loss': 1.0343, 'learning_rate': 0.00010825793454723325, 'epoch': 1.72}        \n{'loss': 1.0548, 'learning_rate': 0.0001, 'epoch': 1.78}                        \n{'loss': 0.9681, 'learning_rate': 9.174206545276677e-05, 'epoch': 1.84}         \n{'loss': 1.0089, 'learning_rate': 8.35405409719266e-05, 'epoch': 1.9}           \n{'loss': 1.0544, 'learning_rate': 7.54514512859201e-05, 'epoch': 1.96}          \n{'loss': 1.0192, 'learning_rate': 6.753005307953167e-05, 'epoch': 2.01}         \n 71%|██████████████████████████████▍            | 34/48 [17:34<07:12, 30.89s/it][2023-12-22 06:02:15,793] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:500] [RANK:1] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 06:02:15,794] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:499] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 06:02:15,794] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:500] [RANK:1] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n[2023-12-22 06:02:15,796] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:499] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 126764\u001b[39m\n{'loss': 0.9535, 'learning_rate': 5.983045753470308e-05, 'epoch': 2.06}         \n{'loss': 0.8908, 'learning_rate': 5.240526069629265e-05, 'epoch': 2.12}         \n{'loss': 0.9635, 'learning_rate': 4.530518418775733e-05, 'epoch': 2.18}         \n{'loss': 0.9131, 'learning_rate': 3.857872873103322e-05, 'epoch': 2.24}         \n{'loss': 0.9077, 'learning_rate': 3.227184283742591e-05, 'epoch': 2.3}          \n{'loss': 0.959, 'learning_rate': 2.6427608932686843e-05, 'epoch': 2.36}         \n 83%|███████████████████████████████████▊       | 40/48 [20:38<04:06, 30.76s/it]\n  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.6767983436584473, 'eval_runtime': 4.8079, 'eval_samples_per_second': 1.664, 'eval_steps_per_second': 0.416, 'epoch': 2.36}\n 83%|███████████████████████████████████▊       | 40/48 [20:43<04:06, 30.76s/it]\n100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.29it/s]\u001b[A\n{'loss': 0.8875, 'learning_rate': 2.1085949060360654e-05, 'epoch': 2.42}        \u001b[A\n{'loss': 0.8347, 'learning_rate': 1.6283352173747145e-05, 'epoch': 2.48}        \n{'loss': 0.9116, 'learning_rate': 1.2052624879351104e-05, 'epoch': 2.54}        \n{'loss': 0.9048, 'learning_rate': 8.422667334494249e-06, 'epoch': 2.6}          \n{'loss': 0.9613, 'learning_rate': 5.418275829936537e-06, 'epoch': 2.66}         \n{'loss': 0.8757, 'learning_rate': 3.059973406066963e-06, 'epoch': 2.72}         \n{'loss': 0.9145, 'learning_rate': 1.3638696597277679e-06, 'epoch': 2.78}        \n{'loss': 0.9378, 'learning_rate': 3.415506993330153e-07, 'epoch': 2.84}         \n{'train_runtime': 1525.2174, 'train_samples_per_second': 1.526, 'train_steps_per_second': 0.031, 'train_loss': 1.3979945220053196, 'epoch': 2.84}\n100%|███████████████████████████████████████████| 48/48 [24:54<00:00, 31.15s/it]\n[2023-12-22 06:09:36,547] [INFO] [axolotl.train.log:61] [PID:499] [RANK:0] Training Completed!!! Saving pre-trained model to ./qlora-out\u001b[39m\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job\n\u001b[34m\u001b[1mwandb\u001b[0m: | 0.002 MB of 0.067 MB uploaded\n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▁\n\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▁█\n\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second █▁\n\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second █▁\n\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████\n\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ▂▂▃▄▄▆▇▇███████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ███▇▇▆▅▅▄▃▃▂▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.6768\n\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 4.8079\n\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 1.664\n\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.416\n\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 2.84\n\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 48\n\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.9378\n\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 3.3948166684409856e+16\n\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.39799\n\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 1525.2174\n\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 1.526\n\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.031\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdry-sky-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/sk4467/physigenai-mistral7b/runs/qjreapkd\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231222_054411-qjreapkd/logs\u001b[0m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import HfApi\napi = HfApi()","metadata":{"execution":{"iopub.status.busy":"2023-12-22T06:37:47.948473Z","iopub.execute_input":"2023-12-22T06:37:47.948906Z","iopub.status.idle":"2023-12-22T06:37:47.954309Z","shell.execute_reply.started":"2023-12-22T06:37:47.948867Z","shell.execute_reply":"2023-12-22T06:37:47.953179Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"api.upload_folder(\n    folder_path=\"/kaggle/working/axolotl/qlora-out\",\n    repo_id=\"ashu3984/PHYSIGEN-AI-Mistral7B\",\n    repo_type=\"model\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T06:39:01.314096Z","iopub.execute_input":"2023-12-22T06:39:01.314501Z","iopub.status.idle":"2023-12-22T06:39:21.170136Z","shell.execute_reply.started":"2023-12-22T06:39:01.314471Z","shell.execute_reply":"2023-12-22T06:39:21.169201Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload 15 LFS files:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a65b13a16b094dbf9500985df28be12f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/336M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbe86c3521cd4c41b2cacd06dc805749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"optimizer.pt:   0%|          | 0.00/169M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b382b80cc9bc4dd98ad2206f36dad51d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"rng_state_0.pth:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f10fb107e08b4b72b74b9f498954e257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.bin:   0%|          | 0.00/336M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81f36876d4be472e89f2cc4e129244a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/336M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0853de8ffa684103b14a0be5a6eb3315"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"rng_state_1.pth:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a50aaff7a1043528d1e0251dfdd5e7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler.pt:   0%|          | 0.00/627 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83822f1e24534e4dab352635b894bd37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.73k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd1d5a8ed87345e9a6c68ec3a3fb99fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/336M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9aeaeae69db406dae22ff449f38d6c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"optimizer.pt:   0%|          | 0.00/169M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31d88e3e40424bff88cce7331e5714d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"rng_state_0.pth:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3f4bd160c5c46e3a81fc80e0ce54e85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"rng_state_1.pth:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9580143144c74c6fbf8d984fb256ceda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler.pt:   0%|          | 0.00/627 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"617fbfefb1cb41eca3ee9dabf39b7c95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.73k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"622ff4c6380a4b0d8a6a15e6a7e27c74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.73k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05c9d03b6e6f4a6c9c1ab6f36ab99d46"}},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/ashu3984/PHYSIGEN-AI-Mistral7B/tree/main/'"},"metadata":{}}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-12-22T06:45:08.760135Z","iopub.execute_input":"2023-12-22T06:45:08.760516Z","iopub.status.idle":"2023-12-22T06:45:08.766648Z","shell.execute_reply.started":"2023-12-22T06:45:08.760484Z","shell.execute_reply":"2023-12-22T06:45:08.765874Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer,pipeline\n\n# Load the lora model\n\npeft_model_id = \"qlora-out\"\nconfig = PeftConfig.from_pretrained(peft_model_id)\n\nmodel = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, device_map={\"\":0}, load_in_8bit=True)\ntokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path,add_bos_token=True,)\ninference_lora_model = PeftModel.from_pretrained(model, peft_model_id, device_map={\"\":0})\n\nquery=\"\"\"Generate a medium difficulty physics question on the topic of Modern Physics, subtopic Photoelectric Effect, that tests conceptual understanding skills. \"\"\"\ntext_gen = pipeline(task=\"text-generation\", model=inference_lora_model, tokenizer=tokenizer, max_length=4096)\noutput = text_gen(f\"<s>[INST] {query} [/INST]\")\nprint(output[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2023-12-22T06:45:12.090162Z","iopub.execute_input":"2023-12-22T06:45:12.090898Z","iopub.status.idle":"2023-12-22T06:45:14.363408Z","shell.execute_reply.started":"2023-12-22T06:45:12.090856Z","shell.execute_reply":"2023-12-22T06:45:14.361942Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4bc719170f24055b216597efbd4003a"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m peft_model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqlora-out\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m config \u001b[38;5;241m=\u001b[39m PeftConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(peft_model_id)\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(config\u001b[38;5;241m.\u001b[39mbase_model_name_or_path,add_bos_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,)\n\u001b[1;32m     12\u001b[0m inference_lora_model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model, peft_model_id, device_map\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m})\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3706\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3698\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3699\u001b[0m     (\n\u001b[1;32m   3700\u001b[0m         model,\n\u001b[1;32m   3701\u001b[0m         missing_keys,\n\u001b[1;32m   3702\u001b[0m         unexpected_keys,\n\u001b[1;32m   3703\u001b[0m         mismatched_keys,\n\u001b[1;32m   3704\u001b[0m         offload_index,\n\u001b[1;32m   3705\u001b[0m         error_msgs,\n\u001b[0;32m-> 3706\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3713\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3714\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3717\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3718\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3724\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   3725\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4116\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   4112\u001b[0m                     set_module_quantized_tensor_to_device(\n\u001b[1;32m   4113\u001b[0m                         model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4114\u001b[0m                     )\n\u001b[1;32m   4115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4116\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4121\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4122\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4123\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4124\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4126\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_quantized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4130\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4131\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4132\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:786\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, is_quantized, is_safetensors, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m    783\u001b[0m             fp16_statistics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCB\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m param_name:\n\u001b[0;32m--> 786\u001b[0m             \u001b[43mset_module_quantized_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, offload_index, state_dict_index\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/integrations/bitsandbytes.py:108\u001b[0m, in \u001b[0;36mset_module_quantized_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, fp16_statistics)\u001b[0m\n\u001b[1;32m    106\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m old_value\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 108\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 14.76 GiB total capacity; 13.87 GiB already allocated; 115.75 MiB free; 13.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 14.76 GiB total capacity; 13.87 GiB already allocated; 115.75 MiB free; 13.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-12-22T06:48:41.842159Z","iopub.execute_input":"2023-12-22T06:48:41.842954Z","iopub.status.idle":"2023-12-22T06:48:43.087658Z","shell.execute_reply.started":"2023-12-22T06:48:41.842921Z","shell.execute_reply":"2023-12-22T06:48:43.086457Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"python: can't open file '/kaggle/working/axolotl/generate.py': [Errno 2] No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/sam-ai/indic-infrex.git","metadata":{"execution":{"iopub.status.busy":"2023-12-22T06:49:44.450554Z","iopub.execute_input":"2023-12-22T06:49:44.451470Z","iopub.status.idle":"2023-12-22T06:49:46.273465Z","shell.execute_reply.started":"2023-12-22T06:49:44.451431Z","shell.execute_reply":"2023-12-22T06:49:46.272415Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Cloning into 'indic-infrex'...\nremote: Enumerating objects: 112, done.\u001b[K\nremote: Counting objects: 100% (112/112), done.\u001b[K\nremote: Compressing objects: 100% (85/85), done.\u001b[K\nremote: Total 112 (delta 55), reused 62 (delta 25), pack-reused 0\u001b[K\nReceiving objects: 100% (112/112), 1.03 MiB | 7.84 MiB/s, done.\nResolving deltas: 100% (55/55), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/axolotl/indic-infrex","metadata":{"execution":{"iopub.status.busy":"2023-12-22T06:50:57.954062Z","iopub.execute_input":"2023-12-22T06:50:57.954840Z","iopub.status.idle":"2023-12-22T06:50:57.960783Z","shell.execute_reply.started":"2023-12-22T06:50:57.954796Z","shell.execute_reply":"2023-12-22T06:50:57.959883Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"/kaggle/working/axolotl/indic-infrex\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-12-22T06:51:12.970070Z","iopub.execute_input":"2023-12-22T06:51:12.970981Z","iopub.status.idle":"2023-12-22T06:52:04.362574Z","shell.execute_reply.started":"2023-12-22T06:51:12.970946Z","shell.execute_reply":"2023-12-22T06:52:04.361174Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"!python generate.py \\\n    --load_8bit \\\n    --base_model 'teknium/OpenHermes-2.5-Mistral-7B' \\\n    --lora_weights 'ashu3984/PHYSIGEN-AI-Mistral7B' \\\n    --share_gradio","metadata":{"execution":{"iopub.status.busy":"2023-12-22T06:52:18.156239Z","iopub.execute_input":"2023-12-22T06:52:18.156649Z","iopub.status.idle":"2023-12-22T06:52:32.621736Z","shell.execute_reply.started":"2023-12-22T06:52:18.156614Z","shell.execute_reply":"2023-12-22T06:52:32.620712Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nTraceback (most recent call last):\n  File \"/kaggle/working/axolotl/indic-infrex/generate.py\", line 207, in <module>\n    main()\n  File \"/kaggle/working/axolotl/indic-infrex/generate.py\", line 49, in main\n    model = model_class.from_pretrained(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 3622, in from_pretrained\n    max_memory = get_balanced_memory(\n  File \"/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py\", line 849, in get_balanced_memory\n    max_memory = get_max_memory(max_memory)\n  File \"/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py\", line 720, in get_max_memory\n    _ = torch.tensor([0], device=i)\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}